@misc{Deivasigamani2020,
author = {Deivasigamani, Karthik},
title = {Retail Graph — Walmart’s Product Knowledge Graph},
year = {2020},
publisher = {Medium},
url = {https://medium.com/walmartglobaltech/retail-graph-walmarts-product-knowledge-graph-6ef7357963bc}
}

@article{relation,
title = {Learning Entity and Relation Embeddings for Knowledge Resolution},
journal = {Procedia Computer Science},
volume = {108},
pages = {345-354},
year = {2017},
note = {International Conference on Computational Science, ICCS 2017, 12-14 June 2017, Zurich, Switzerland},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.05.045},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917305628},
author = {Hailun Lin and Yong Liu and Weiping Wang and Yinliang Yue and Zheng Lin},
keywords = {knowledge graph, knowledge resolution, knowledge representation, entity embedding, relation embedding},
abstract = {Knowledge resolution is the task of clustering knowledge mentions, e.g., entity and relation mentions into several disjoint groups with each group representing a unique entity or relation. Such resolution is a central step in constructing high-quality knowledge graph from unstructured text. Previous research has tackled this problem by making use of various textual and structural features from a semantic dictionary or a knowledge graph. This may lead to poor performance on knowledge mentions with poor or not well-known contexts. In addition, it is also limited by the coverage of the semantic dictionary or knowledge graph. In this work, we propose ETransR, a method which automatically learns entity and relation feature representations in continuous vector spaces, in order to measure the semantic relatedness of knowledge mentions for knowledge resolution. Experimental results on two benchmark datasets show that our proposed method delivers significant improvements compared with the state-of-the-art baselines on the task of knowledge resolution.}
}

@misc{doc2vec,
      title={Distributed Representations of Sentences and Documents}, 
      author={Quoc V. Le and Tomas Mikolov},
      year={2014},
      eprint={1405.4053},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{t5,
      title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer}, 
      author={Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
      year={2020},
      eprint={1910.10683},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}